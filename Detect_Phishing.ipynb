{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Cargando las librerias a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "from string import printable\n",
    "from sklearn import model_selection\n",
    "\n",
    "#import gensim\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda, Flatten\n",
    "from keras.layers import Input, ELU, LSTM, Embedding, Convolution2D, MaxPooling2D, \\\n",
    "BatchNormalization, Convolution1D, MaxPooling1D, concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>isMalicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32656</td>\n",
       "      <td>translink.com.au/plan-your-journey/timetables/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  isMalicious\n",
       "32656  translink.com.au/plan-your-journey/timetables/...            0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cargar los datos de la base de datos\n",
    "DATA_HOME = 'data/'\n",
    "df = pd.read_csv(DATA_HOME + 'data_url.csv')\n",
    "\n",
    "DATA_HOME = 'model/'\n",
    "df.sample().head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando la data (1 item)\n",
    "Cada **caracter imprimible** tiene una representación en Ascii, pero para facilitar su uso en python , en vez de mostrarnos su valor en ASCII, lo que haremos será, mostrarnos el valor que ocupa en un diccionario ya definido en python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printable.index(\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17],\n",
       " [25],\n",
       " [25],\n",
       " [17],\n",
       " [22],\n",
       " [15],\n",
       " [76],\n",
       " [13],\n",
       " [25],\n",
       " [23],\n",
       " [77],\n",
       " [50],\n",
       " [10],\n",
       " [6]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tengamos en cuenta que sumaremos 1 para que los valores no empiecen con 0\n",
    "\n",
    "hola=\"google.com/N95\"\n",
    "\n",
    "url_int_tokens = [[(printable.index(x) + 1) for x in url if x in printable] for url in hola]\n",
    "url_int_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando la data (Todos los items)\n",
    "* Cada **caracter imprimible** tiene una representación en Ascii, pero para facilitar su uso en python , en vez de mostrarnos su valor en ASCII, lo que haremos será, mostrarnos el valor que ocupa en un diccionario ya definido en python\n",
    "* Ademas vamos a restringir la cantidad de caracteres a 75, si son menos, se rellenaran con 0\n",
    "* Luego pondremos todos esos valores en una matriz, es con esa matriz, con la cual vamos a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Convierta una cadena URL sin procesar en la lista de listas donde los caracteres contenidos\n",
    "#         en \"imprimible\" se almacenan codificados como enteros [ASCII]\n",
    "\n",
    "url_int_tokens = [[(printable.index(x) + 1) for x in url if x in printable] for url in df.url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: corte la cadena de URL en max_len o rellene con ceros si es más corter\n",
    "\"\"\"Esta función transforma una lista (de longitud num_samples) de secuencias (listas de enteros) \n",
    "en una matriz 2D de Numpy de forma (num_samples, num_timesteps). num_timesteps es el argumento \n",
    "maxlen si se proporciona o la longitud de la secuencia más larga de la lista. Las secuencias que son más \n",
    "cortas que num_timesteps se rellenan con valor hasta que son num_timesteps de largo. Las secuencias más largas que\n",
    "num_timesteps se truncan para que se ajusten a la longitud deseada. La posición donde ocurre el relleno o \n",
    "el truncamiento está determinada por los argumentos de relleno y trunca\"\"\"\n",
    "max_len=100\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions of X:  (212835, 100) Vector dimension of target:  (212835,)\n"
     ]
    }
   ],
   "source": [
    "# Paso 3: Volcar las etiquetas de df a una matriz numpy\n",
    "\n",
    "target = np.array(df.isMalicious)\n",
    "\n",
    "print('Matrix dimensions of X: ', X.shape, 'Vector dimension of target: ', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Cross-Validation: Split the data set into training and test data\n",
    "X_train, X_test, target_train, target_test = model_selection.train_test_split(X, target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0, 14, 15, 12, 15, 29, 31, 13, 18, 15, 28, 77,\n",
       "        32, 15, 28, 11, 24, 29, 30, 11, 22, 30, 31, 24, 17, 29, 14, 15,\n",
       "        30, 11, 19, 22, 29, 77, 30, 15, 28, 23, 19, 24, 77,  2,  4, 10,\n",
       "         2, 77, 11, 77, 29, 18, 25, 33, 15, 32, 15, 24, 30, 77, 13, 77,\n",
       "        42, 11, 19, 28],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, 23, 35, 30, 18, 19, 28, 30, 35, 25, 24, 15, 76, 13, 25,\n",
       "        23, 77, 19, 24, 16, 25, 77, 44, 25, 29, 30, 15, 29, 29, 54, 15,\n",
       "        33, 11, 28, 14, 29, 65, 18, 25, 29, 30, 15, 29, 29, 75, 13, 28,\n",
       "        15, 14, 19, 30],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15, 22, 26, 15, 28,\n",
       "        19, 25, 14, 19, 13, 25, 76, 13, 25, 23, 77, 15, 29, 77, 24, 25,\n",
       "        30, 19, 13, 19, 11, 29, 77, 25, 24, 12, 11, 28, 13, 15, 22, 25,\n",
       "        24, 11, 77, 13, 25, 13, 19, 24, 11, 29, 77, 13, 25, 23, 25, 75,\n",
       "        17, 31, 29, 30, 11, 75, 23, 11, 29, 11, 75, 26, 19, 36, 36, 11,\n",
       "        75, 16, 19, 24, 11, 75, 17, 28, 31, 15, 29, 11, 75,  6, 10,  1,\n",
       "         1,  4,  4,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0, 20, 23, 15, 30, 11, 22, 22, 25, 35, 29,\n",
       "        22, 22, 26, 76, 13, 25, 23, 77,  8, 17,  7, 12, 31, 12, 30,  8,\n",
       "        32, 83, 57, 54, 24, 35, 42, 54, 13, 81, 59, 35, 12, 35, 44, 55,\n",
       "        14, 38, 47, 55],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,\n",
       "        26, 28, 19, 23, 15, 76, 28, 31, 77, 23, 76,  2, 26, 28, 19, 23,\n",
       "        15, 76, 28, 31]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disposiciones generales para todos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL get layer dimensions for any model!\n",
    "def print_layers_dims(model):\n",
    "    l_layers = model.layers\n",
    "    # Note None is ALWAYS batch_size\n",
    "    for i in range(len(l_layers)):\n",
    "        print(l_layers[i])\n",
    "        print('Input Shape: ', l_layers[i].input_shape, 'Output Shape: ', l_layers[i].output_shape)\n",
    "\n",
    "# GENERAL save model to disk function!\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    #have h5py installed\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)\n",
    "    \n",
    "\n",
    "# GENERAL load model from disk function!\n",
    "def load_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    with open(fileModelJSON, 'r') as f:\n",
    "         model_json = json.load(f)\n",
    "         model = model_from_json(model_json)\n",
    "    \n",
    "    model.load_weights(fileWeights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 01- 1D Convolutions and Fully Connected Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_fully(max_len=100, emb_dim=50, max_vocab_len=100, W_reg=regularizers.l2(1e-4)):\n",
    "    # Input\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    # Embedding layer\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "                W_regularizer=W_reg)(main_input) \n",
    "    emb = Dropout(0.25)(emb)\n",
    "\n",
    "    \n",
    "    def sum_1d(X):\n",
    "        return K.sum(X, axis=1)\n",
    "    \n",
    "    def get_conv_layer(emb, kernel_size=5, filters=256):\n",
    "        # Conv layer\n",
    "        conv = Convolution1D(kernel_size=kernel_size, filters=filters, \\\n",
    "                     border_mode='same')(emb)\n",
    "        conv = ELU()(conv)\n",
    "\n",
    "        conv = Lambda(sum_1d, output_shape=(filters,))(conv)\n",
    "        #conv = BatchNormalization(mode=0)(conv)\n",
    "        conv = Dropout(0.5)(conv)\n",
    "        return conv\n",
    "        \n",
    "    # Multiple Conv Layers\n",
    "    \n",
    "    # calling custom conv function from above\n",
    "    conv1 = get_conv_layer(emb, kernel_size=2, filters=256)\n",
    "    conv2 = get_conv_layer(emb, kernel_size=3, filters=256)\n",
    "    conv3 = get_conv_layer(emb, kernel_size=4, filters=256)\n",
    "    conv4 = get_conv_layer(emb, kernel_size=5, filters=256)\n",
    "\n",
    "    # Fully Connected Layers (linear)\n",
    "    merged = concatenate([conv1,conv2,conv3,conv4], axis=1)\n",
    "\n",
    "    hidden1 = Dense(1024)(merged)\n",
    "    hidden1 = ELU()(hidden1)\n",
    "    hidden1 = BatchNormalization(mode=0)(hidden1)\n",
    "    hidden1 = Dropout(0.5)(hidden1)\n",
    "\n",
    "    hidden2 = Dense(1024)(hidden1)\n",
    "    hidden2 = ELU()(hidden2)\n",
    "    hidden2 = BatchNormalization(mode=0)(hidden2)\n",
    "    hidden2 = Dropout(0.5)(hidden2)\n",
    "    \n",
    "    # Output layer (last fully connected layer)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(hidden2)\n",
    "\n",
    "    # Compile model and define optimizer\n",
    "    model = Model(input=[main_input], output=[output])\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159626/159626 [==============================] - 1084s 7ms/step - loss: 0.6390 - accuracy: 0.6843\n",
      "Epoch 2/20\n",
      "159626/159626 [==============================] - 1078s 7ms/step - loss: 0.4955 - accuracy: 0.7590\n",
      "Epoch 3/20\n",
      "159626/159626 [==============================] - 1082s 7ms/step - loss: 0.4559 - accuracy: 0.7851\n",
      "Epoch 4/20\n",
      "159626/159626 [==============================] - 1045s 7ms/step - loss: 0.4358 - accuracy: 0.7963\n",
      "Epoch 5/20\n",
      "159626/159626 [==============================] - 1062s 7ms/step - loss: 0.4220 - accuracy: 0.8026\n",
      "Epoch 6/20\n",
      "159626/159626 [==============================] - 1189s 7ms/step - loss: 0.4138 - accuracy: 0.8067\n",
      "Epoch 7/20\n",
      "159626/159626 [==============================] - 1090s 7ms/step - loss: 0.4089 - accuracy: 0.8089\n",
      "Epoch 8/20\n",
      "159626/159626 [==============================] - 1112s 7ms/step - loss: 0.4014 - accuracy: 0.8140\n",
      "Epoch 9/20\n",
      "159626/159626 [==============================] - 1036s 6ms/step - loss: 0.3962 - accuracy: 0.8161\n",
      "Epoch 10/20\n",
      "159626/159626 [==============================] - 1147s 7ms/step - loss: 0.3930 - accuracy: 0.8193\n",
      "Epoch 11/20\n",
      "159626/159626 [==============================] - 1002s 6ms/step - loss: 0.3892 - accuracy: 0.8206\n",
      "Epoch 12/20\n",
      "159626/159626 [==============================] - 1203s 8ms/step - loss: 0.3870 - accuracy: 0.8226\n",
      "Epoch 13/20\n",
      "159626/159626 [==============================] - 1095s 7ms/step - loss: 0.3820 - accuracy: 0.8249\n",
      "Epoch 14/20\n",
      "159626/159626 [==============================] - 1054s 7ms/step - loss: 0.3813 - accuracy: 0.8255\n",
      "Epoch 15/20\n",
      "159626/159626 [==============================] - 1096s 7ms/step - loss: 0.3748 - accuracy: 0.8297\n",
      "Epoch 16/20\n",
      "159626/159626 [==============================] - 1222s 8ms/step - loss: 0.3703 - accuracy: 0.8324\n",
      "Epoch 17/20\n",
      "159626/159626 [==============================] - 1446s 9ms/step - loss: 0.3654 - accuracy: 0.8352\n",
      "Epoch 18/20\n",
      "159626/159626 [==============================] - 1091s 7ms/step - loss: 0.3606 - accuracy: 0.8379\n",
      "Epoch 19/20\n",
      "159626/159626 [==============================] - 1216s 8ms/step - loss: 0.3556 - accuracy: 0.8399\n",
      "Epoch 20/20\n",
      "159626/159626 [==============================] - 2539s 16ms/step - loss: 0.3521 - accuracy: 0.8424\n",
      "53209/53209 [==============================] - 130s 2ms/step\n",
      "\n",
      "Final Cross-Validation Accuracy 0.8620910048484802 \n",
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001288949FD48>\n",
      "Input Shape:  (None, 100) Output Shape:  (None, 100)\n",
      "<keras.layers.embeddings.Embedding object at 0x000001288949F308>\n",
      "Input Shape:  (None, 100) Output Shape:  (None, 100, 50)\n",
      "<keras.layers.core.Dropout object at 0x000001288949F3C8>\n",
      "Input Shape:  (None, 100, 50) Output Shape:  (None, 100, 50)\n",
      "<keras.layers.convolutional.Conv1D object at 0x000001288949F608>\n",
      "Input Shape:  (None, 100, 50) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.convolutional.Conv1D object at 0x0000012889449748>\n",
      "Input Shape:  (None, 100, 50) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.convolutional.Conv1D object at 0x0000012889E33208>\n",
      "Input Shape:  (None, 100, 50) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.convolutional.Conv1D object at 0x000001288A9412C8>\n",
      "Input Shape:  (None, 100, 50) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000001288949F388>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x0000012889F754C8>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x0000012889587AC8>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000001288A946948>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.core.Lambda object at 0x00000128897FE8C8>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Lambda object at 0x0000012889E47248>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Lambda object at 0x000001288A9199C8>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Lambda object at 0x000001288A951BC8>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x00000128847233C8>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x0000012888854048>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x000001288A9194C8>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x000001288A9516C8>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.merge.Concatenate object at 0x000001288A978C48>\n",
      "Input Shape:  [(None, 256), (None, 256), (None, 256), (None, 256)] Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dense object at 0x000001288A981B08>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000001288A9AE788>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001288A9AEA48>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dropout object at 0x000001288A9B4248>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dense object at 0x000001288A9BA208>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000001288A9D4348>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001288A9F4D88>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dropout object at 0x000001288A9F4CC8>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dense object at 0x000001288AA24488>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1)\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "model = conv_fully()\n",
    "model.fit(X_train, target_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = model.evaluate(X_test, target_test, verbose=1)\n",
    "\n",
    "print('\\nFinal Cross-Validation Accuracy', accuracy, '\\n')\n",
    "print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa con un modelo similar\n",
    "\n",
    "``` conv_fully(max_len=75, emb_dim=32, max_vocab_len=100, W_reg=regularizers.l2(1e-4)):```\n",
    "\n",
    "\n",
    "*Embedding layer\n",
    "*Input_dim :: 100\n",
    "*Output_dim :: 32\n",
    "*Input_length :: 75\n",
    "*epochs :: 20\n",
    "*batch_size :: 32\n",
    "\n",
    "\n",
    "### Final Cross-Validation Accuracy 0.8544043302536011 \n",
    "\n",
    "```\n",
    "<keras.engine.input_layer.InputLayer object at 0x00000128F4636D48>\n",
    "Input Shape:  (None, 75) Output Shape:  (None, 75)\n",
    "<keras.layers.embeddings.Embedding object at 0x00000128D2E9E388>\n",
    "Input Shape:  (None, 75) Output Shape:  (None, 75, 32)\n",
    "<keras.layers.core.Dropout object at 0x00000128D2E9E408>\n",
    "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 32)\n",
    "<keras.layers.convolutional.Conv1D object at 0x00000128D2E9EA48>\n",
    "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.convolutional.Conv1D object at 0x00000128D2ED1588>\n",
    "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.convolutional.Conv1D object at 0x00000128D2F094C8>\n",
    "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.convolutional.Conv1D object at 0x00000128D2F41FC8>\n",
    "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.advanced_activations.ELU object at 0x00000128D2E9E3C8>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.advanced_activations.ELU object at 0x00000128D2EDB388>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.advanced_activations.ELU object at 0x00000128D2F0B6C8>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.advanced_activations.ELU object at 0x00000128D2F4F388>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.core.Lambda object at 0x00000128D2EA7AC8>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.core.Lambda object at 0x00000128D2EDFB08>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.core.Lambda object at 0x00000128D2F17D08>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.core.Lambda object at 0x00000128D2F4EF08>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.core.Dropout object at 0x00000128D2EB4EC8>\n",
    "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.core.Dropout object at 0x00000128D2EDF5C8>\n",
    "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.core.Dropout object at 0x00000128D2F26088>\n",
    "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.core.Dropout object at 0x00000128D2F5D408>\n",
    "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
    "<keras.layers.merge.Concatenate object at 0x00000128D2F82608>\n",
    "Input Shape:  [(None, 256), (None, 256), (None, 256), (None, 256)] Output Shape:  (None, 1024)\n",
    "<keras.layers.core.Dense object at 0x00000128D2F7D388>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.advanced_activations.ELU object at 0x00000128D2FB1CC8>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.normalization.BatchNormalization object at 0x00000128D2FB1D88>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.core.Dropout object at 0x00000128D2FB1948>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.core.Dense object at 0x00000128D2FBD188>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.advanced_activations.ELU object at 0x00000128D2FDA748>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.normalization.BatchNormalization object at 0x00000128D3042C08>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.core.Dropout object at 0x00000128D3042948>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
    "<keras.layers.core.Dense object at 0x00000128D3070848>\n",
    "Input Shape:  (None, 1024) Output Shape:  (None, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deeplearning_1DConv\"\n",
    "save_model(DATA_HOME + model_name + \".json\", DATA_HOME + model_name + \".h5\")\n",
    "model = load_model(DATA_HOME + model_name + \".json\", DATA_HOME + model_name + \".h5\")\n",
    "#print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url_mal1 = \"www.facel00k.com/mlost1/\"\n",
    "test_url_ben1 = \"www.facebook.com/mlost1/\"\n",
    "test_url_mal2 = \"naureen.net/etisalat.ae/index2.php\"\n",
    "test_url_ben2 = \"sixt.com/php/reservation?language=en_US\"\n",
    "\n",
    "url = np.array([test_url_ben1,test_url_mal1,test_url_ben2,test_url_mal2])\n",
    "\n",
    "#Tokenizamos\n",
    "max_len=100\n",
    "url_int_tokens = [[printable.index(x) + 1 for x in url if x in printable]for url in url]\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La página www.facebook.com/mlost1/ \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.74 %\n",
      "La página www.facel00k.com/mlost1/ \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.67 %\n",
      "La página sixt.com/php/reservation?language=en_US \t es segura \n",
      "\t con la probabilidad de que sea phishing del  0.08 %\n",
      "La página naureen.net/etisalat.ae/index2.php \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.88 %\n"
     ]
    }
   ],
   "source": [
    "proba = model.predict(X, batch_size=1)\n",
    "def print_result(proba,x):\n",
    "    if float(proba[x]) > 0.5:\n",
    "        return \"no es segura\"\n",
    "    else:\n",
    "        return \"es segura\"\n",
    "\n",
    "\n",
    "    \n",
    "for x in range(len(url)):\n",
    "    print(\"La página\",url[x],\"\\t\", print_result(proba,x),\"\\n\\t con la probabilidad de que sea phishing del \",\\\n",
    "          round(float(proba[x]),2), \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get for example word2vec embedding weight matix\n",
    "# l_layers = model.layers\n",
    "# weights = l_layers[1].get_weights()\n",
    "# weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 02 - 1D Convolution and LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer\n",
    "#  Input_dim :: Cantidad de Caracteres difirentes a utilizar palabras en el diccionario\n",
    "#  Output_dim :: Dimensión de un vector de incrustación (para cada caracter seleccionado)\n",
    "#  Input_length :: Cantidad de caracteres que se van a recibir (Es decir cantidad de caracteres que se leeran para la predicción)\n",
    "\n",
    "def lstm_conv(max_len=100, emb_dim=50, max_vocab_len=100, lstm_output_size=50, W_reg=regularizers.l2(1e-4)):\n",
    "    \n",
    "    # Input\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    \n",
    "    # Embedding layer\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "                W_regularizer=W_reg)(main_input) \n",
    "    emb = Dropout(0.25)(emb)\n",
    "\n",
    "    # Conv layer\n",
    "    conv = Convolution1D(kernel_size=5, filters=256, \\\n",
    "                     border_mode='same')(emb)\n",
    "    conv = ELU()(conv)\n",
    "\n",
    "    conv = MaxPooling1D(pool_size=4)(conv)\n",
    "    conv = Dropout(0.5)(conv)\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm = LSTM(lstm_output_size)(conv)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    # Output layer (last fully connected layer)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(lstm)\n",
    "\n",
    "    # Compile model and define optimizer\n",
    "    model = Model(input=[main_input], output=[output])\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159626/159626 [==============================] - 586s 4ms/step - loss: 0.4099 - accuracy: 0.8110\n",
      "Epoch 2/20\n",
      "159626/159626 [==============================] - 658s 4ms/step - loss: 0.3020 - accuracy: 0.8745\n",
      "Epoch 3/20\n",
      "159626/159626 [==============================] - 609s 4ms/step - loss: 0.2670 - accuracy: 0.8926\n",
      "Epoch 4/20\n",
      "159626/159626 [==============================] - 566s 4ms/step - loss: 0.2437 - accuracy: 0.9018\n",
      "Epoch 5/20\n",
      "159626/159626 [==============================] - 596s 4ms/step - loss: 0.2294 - accuracy: 0.9084\n",
      "Epoch 6/20\n",
      "159626/159626 [==============================] - 616s 4ms/step - loss: 0.2173 - accuracy: 0.9142\n",
      "Epoch 7/20\n",
      "159626/159626 [==============================] - 645s 4ms/step - loss: 0.2098 - accuracy: 0.9163\n",
      "Epoch 8/20\n",
      "159626/159626 [==============================] - 636s 4ms/step - loss: 0.2023 - accuracy: 0.9204\n",
      "Epoch 9/20\n",
      "159626/159626 [==============================] - 586s 4ms/step - loss: 0.1972 - accuracy: 0.9225\n",
      "Epoch 10/20\n",
      "159626/159626 [==============================] - 571s 4ms/step - loss: 0.1921 - accuracy: 0.9244\n",
      "Epoch 11/20\n",
      "159626/159626 [==============================] - 613s 4ms/step - loss: 0.1883 - accuracy: 0.9271\n",
      "Epoch 12/20\n",
      "159626/159626 [==============================] - 599s 4ms/step - loss: 0.1842 - accuracy: 0.9283\n",
      "Epoch 13/20\n",
      "159626/159626 [==============================] - 576s 4ms/step - loss: 0.1801 - accuracy: 0.9297\n",
      "Epoch 14/20\n",
      "159626/159626 [==============================] - 573s 4ms/step - loss: 0.1772 - accuracy: 0.9314\n",
      "Epoch 15/20\n",
      "159626/159626 [==============================] - 575s 4ms/step - loss: 0.1746 - accuracy: 0.9320\n",
      "Epoch 16/20\n",
      "159626/159626 [==============================] - 632s 4ms/step - loss: 0.1722 - accuracy: 0.9335\n",
      "Epoch 17/20\n",
      "159626/159626 [==============================] - 594s 4ms/step - loss: 0.1688 - accuracy: 0.9341\n",
      "Epoch 18/20\n",
      "159626/159626 [==============================] - 631s 4ms/step - loss: 0.1672 - accuracy: 0.9349\n",
      "Epoch 19/20\n",
      "159626/159626 [==============================] - 622s 4ms/step - loss: 0.1642 - accuracy: 0.9371\n",
      "Epoch 20/20\n",
      "159626/159626 [==============================] - 605s 4ms/step - loss: 0.1622 - accuracy: 0.9373\n",
      "53209/53209 [==============================] - 67s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "model2 = lstm_conv()\n",
    "model2.fit(X_train, target_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = model2.evaluate(X_test, target_test, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cross-Validation Accuracy 0.9496889710426331 \n",
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x00000128F7F9A748>\n",
      "Input Shape:  (None, 100) Output Shape:  (None, 100)\n",
      "<keras.layers.embeddings.Embedding object at 0x00000128F7F9A188>\n",
      "Input Shape:  (None, 100) Output Shape:  (None, 100, 50)\n",
      "<keras.layers.core.Dropout object at 0x00000128F7F9A0C8>\n",
      "Input Shape:  (None, 100, 50) Output Shape:  (None, 100, 50)\n",
      "<keras.layers.convolutional.Conv1D object at 0x00000128F7F95FC8>\n",
      "Input Shape:  (None, 100, 50) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x00000128F7FA3988>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 100, 256)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x00000128F7FB0D08>\n",
      "Input Shape:  (None, 100, 256) Output Shape:  (None, 25, 256)\n",
      "<keras.layers.core.Dropout object at 0x00000128DB6F0448>\n",
      "Input Shape:  (None, 25, 256) Output Shape:  (None, 25, 256)\n",
      "<keras.layers.recurrent.LSTM object at 0x00000128DB6E9488>\n",
      "Input Shape:  (None, 25, 256) Output Shape:  (None, 50)\n",
      "<keras.layers.core.Dropout object at 0x00000128DB6F6308>\n",
      "Input Shape:  (None, 50) Output Shape:  (None, 50)\n",
      "<keras.layers.core.Dense object at 0x00000128DB6F6648>\n",
      "Input Shape:  (None, 50) Output Shape:  (None, 1)\n"
     ]
    }
   ],
   "source": [
    "print('\\nFinal Cross-Validation Accuracy', accuracy, '\\n')\n",
    "print_layers_dims(model2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa con un modelo similar\n",
    "\n",
    "```lstm_conv(max_len=75, emb_dim=32, max_vocab_len=100, lstm_output_size=32, W_reg=regularizers.l2(1e-4))```\n",
    "\n",
    "\n",
    "*Embedding layer\n",
    "*Input_dim :: 100\n",
    "*Output_dim :: 32\n",
    "*Input_length :: 75\n",
    "*epochs :: 20\n",
    "*batch_size :: 32\n",
    "\n",
    "\n",
    "### Final Cross-Validation Accuracy 0.9385442137718201 \n",
    "\n",
    "\n",
    "```<keras.engine.input_layer.InputLayer object at 0x00000128D598FC88>\n",
    "Input Shape:  (None, 75) Output Shape:  (None, 75)\n",
    "<keras.layers.embeddings.Embedding object at 0x00000128D59957C8>\n",
    "Input Shape:  (None, 75) Output Shape:  (None, 75, 32)\n",
    "<keras.layers.core.Dropout object at 0x00000128D598F808>\n",
    "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 32)\n",
    "<keras.layers.convolutional.Conv1D object at 0x00000128D598F388>\n",
    "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.advanced_activations.ELU object at 0x00000128D598F8C8>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
    "<keras.layers.pooling.MaxPooling1D object at 0x00000128D5991B88>\n",
    "Input Shape:  (None, 75, 256) Output Shape:  (None, 18, 256)\n",
    "<keras.layers.core.Dropout object at 0x00000128D6642808>\n",
    "Input Shape:  (None, 18, 256) Output Shape:  (None, 18, 256)\n",
    "<keras.layers.recurrent.LSTM object at 0x00000128D664AE88>\n",
    "Input Shape:  (None, 18, 256) Output Shape:  (None, 32)\n",
    "<keras.layers.core.Dropout object at 0x00000128D664DD48>\n",
    "Input Shape:  (None, 32) Output Shape:  (None, 32)\n",
    "<keras.layers.core.Dense object at 0x00000128D6654C88>\n",
    "Input Shape:  (None, 32) Output Shape:  (None, 1)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deeplearning_1DConvLSTM\"\n",
    "save_model(DATA_HOME + model_name + \".json\", DATA_HOME + model_name + \".h5\")\n",
    "model = load_model(DATA_HOME + model_name + \".json\", DATA_HOME + model_name + \".h5\")\n",
    "#print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando una predicción\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url_mal1 = \"www.facel00k.com/mlost1/\"\n",
    "test_url_ben1 = \"www.facebook.com/mlost1/\"\n",
    "test_url_mal2 = \"naureen.net/etisalat.ae/index2.php\"\n",
    "test_url_ben2 = \"sixt.com/php/reservation?language=en_US\"\n",
    "test_url_mal3 = \"tottus.supercupones.net\"\n",
    "test_url_mal4 = \"netfIix.com\"\n",
    "\n",
    "url = np.array([test_url_ben1,test_url_mal1,test_url_ben2,test_url_mal2,test_url_mal3,test_url_mal4])\n",
    "\n",
    "#Tokenizamos\n",
    "max_len=100\n",
    "url_int_tokens = [[printable.index(x) + 1 for x in url if x in printable]for url in url]\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La página www.facebook.com/mlost1/ \t es segura \n",
      "\t con la probabilidad de que sea phishing del  0.34 %\n",
      "La página www.facel00k.com/mlost1/ \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.88 %\n",
      "La página sixt.com/php/reservation?language=en_US \t es segura \n",
      "\t con la probabilidad de que sea phishing del  0.0 %\n",
      "La página naureen.net/etisalat.ae/index2.php \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.99 %\n",
      "La página netflix.com \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.69 %\n",
      "La página tottus.supercupones.net \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.92 %\n",
      "La página netfIix.com \t no es segura \n",
      "\t con la probabilidad de que sea phishing del  0.73 %\n"
     ]
    }
   ],
   "source": [
    "proba = model2.predict(X, batch_size=1)\n",
    "def print_result(proba,x):\n",
    "    if float(proba[x]) > 0.5:\n",
    "        return \"no es segura\"\n",
    "    else:\n",
    "        return \"es segura\"\n",
    "\n",
    "\n",
    "    \n",
    "for x in range(len(url)):\n",
    "    print(\"La página\",url[x],\"\\t\", print_result(proba,x),\"\\n\\t con la probabilidad de que sea phishing del \",\\\n",
    "          round(float(proba[x]),2), \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
